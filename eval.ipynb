{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce96d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.11/site-packages (1.77.0)\n",
      "Requirement already satisfied: rouge-score in /opt/anaconda3/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (4.65.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.11/site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.11/site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (2023.10.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas openai rouge-score tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b663ca5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Set them as environment variables for the current Python process\u001b[39;00m\n\u001b[1;32m     31\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m api_key_value\n\u001b[0;32m---> 32\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_ORG_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m org_id_value\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project_id_value: \u001b[38;5;66;03m# Only set if you have one and it's relevant\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_PROJECT_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m project_id_value\n",
      "File \u001b[0;32m<frozen os>:684\u001b[0m, in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:758\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(value)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and API Key Setup\n",
    "import pandas as pd\n",
    "import openai\n",
    "from rouge_score import rouge_scorer\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm # Use tqdm.notebook for better notebook progress bars\n",
    "import warnings\n",
    "\n",
    "# --- OpenAI API Setup ---\n",
    "# WARNING: If you save this notebook and share it, your API key will be visible.\n",
    "# It's better to use a .env file (see Option 2) or input() for shared notebooks.\n",
    "# For personal use where the notebook isn't shared widely, this is convenient.\n",
    "\n",
    "# --- REPLACE WITH YOUR ACTUAL KEY, ORG ID, AND PROJECT ID ---\n",
    "api_key_value = \"\"\n",
    "org_id_value = \"\"\n",
    "project_id_value = \"\" # Project ID is less commonly needed for basic API calls\n",
    "\n",
    "# Set them as environment variables for the current Python process\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key_value\n",
    "os.environ[\"OPENAI_ORG_ID\"] = org_id_value\n",
    "if project_id_value: # Only set if you have one and it's relevant\n",
    "    os.environ[\"OPENAI_PROJECT_ID\"] = project_id_value\n",
    "\n",
    "# Initialize the OpenAI client. It will pick up the environment variables.\n",
    "try:\n",
    "    client = openai.OpenAI()\n",
    "    # Perform a simple test call to verify authentication (optional but good for debugging)\n",
    "    # client.models.list() \n",
    "    # print(\"OpenAI client initialized and authenticated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing OpenAI client: {e}\")\n",
    "    warnings.warn(\"OpenAI client might not be properly authenticated. Check your API key and organization ID.\")\n",
    "\n",
    "# --- Configuration ---\n",
    "CSV_FILE_PATH = 'reddit_advice_dataset.csv' # Make sure this file is in the same directory as your notebook, or provide the full path\n",
    "OUTPUT_CSV_FILE_PATH = 'reddit_advice_chatgpt_rouge_scores_notebook.csv'\n",
    "\n",
    "# !!! IMPORTANT: Inspect your CSV and set these column names correctly !!!\n",
    "PROMPT_COLUMN_NAME = 'question'  # Replace with the actual column name for the user's prompt\n",
    "HUMAN_ADVICE_COLUMN_NAME = 'suggestion' # Replace with the actual column name for human advice\n",
    "\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "MAX_TOKENS_RESPONSE = 250\n",
    "TEMPERATURE = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11244018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Helper Function for ChatGPT\n",
    "def get_chatgpt_advice(prompt_text):\n",
    "    \"\"\"Generates advice from ChatGPT for a given prompt.\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create( # Use the client initialized in the previous cell\n",
    "            model=OPENAI_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant providing advice.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Please provide advice for the following situation: {prompt_text}\"}\n",
    "            ],\n",
    "            max_tokens=MAX_TOKENS_RESPONSE,\n",
    "            temperature=TEMPERATURE\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling OpenAI API for prompt '{prompt_text[:50]}...': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5a16cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 224 prompts from reddit_advice_dataset.csv\n",
      "Generating ChatGPT responses and calculating ROUGE scores using gpt-4o-mini...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d42ec34bce41109db4128f1b2e3af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Prompts:   0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to reddit_advice_chatgpt_rouge_scores_notebook.csv\n",
      "\n",
      "Average ROUGE F1-Scores (for successfully processed prompts):\n",
      "  ROUGE-1: 0.1849\n",
      "  ROUGE-2: 0.0249\n",
      "  ROUGE-L: 0.0975\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Main Processing Logic\n",
    "def main_notebook_processing():\n",
    "    # Load the dataset\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_FILE_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file not found at {CSV_FILE_PATH}\")\n",
    "        print(\"Please ensure 'reddit_advice_dataset.csv' is in the same directory as the notebook or provide the full path.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loaded {len(df)} prompts from {CSV_FILE_PATH}\")\n",
    "\n",
    "    # Initialize ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    print(f\"Generating ChatGPT responses and calculating ROUGE scores using {OPENAI_MODEL}...\")\n",
    "    # Use tqdm.notebook for a nice progress bar in the notebook\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Prompts\"):\n",
    "        prompt_text = row[PROMPT_COLUMN_NAME]\n",
    "        human_advice_text = str(row[HUMAN_ADVICE_COLUMN_NAME])\n",
    "\n",
    "        if pd.isna(prompt_text) or pd.isna(human_advice_text) or not human_advice_text.strip():\n",
    "            print(f\"Skipping row {index+1} due to missing prompt or human advice.\")\n",
    "            results.append({\n",
    "                'prompt': prompt_text,\n",
    "                'human_advice': human_advice_text,\n",
    "                'chatgpt_advice': \"SKIPPED_EMPTY_INPUT\",\n",
    "                'rouge1_f': 0, 'rouge1_p': 0, 'rouge1_r': 0,\n",
    "                'rouge2_f': 0, 'rougeL_f': 0\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        chatgpt_advice_text = get_chatgpt_advice(prompt_text)\n",
    "\n",
    "        if chatgpt_advice_text:\n",
    "            rouge_scores_dict = scorer.score(target=human_advice_text, prediction=chatgpt_advice_text)\n",
    "            results.append({\n",
    "                'prompt': prompt_text,\n",
    "                'human_advice': human_advice_text,\n",
    "                'chatgpt_advice': chatgpt_advice_text,\n",
    "                'rouge1_f': rouge_scores_dict['rouge1'].fmeasure,\n",
    "                'rouge1_p': rouge_scores_dict['rouge1'].precision,\n",
    "                'rouge1_r': rouge_scores_dict['rouge1'].recall,\n",
    "                'rouge2_f': rouge_scores_dict['rouge2'].fmeasure,\n",
    "                'rougeL_f': rouge_scores_dict['rougeL'].fmeasure\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                'prompt': prompt_text,\n",
    "                'human_advice': human_advice_text,\n",
    "                'chatgpt_advice': \"ERROR_GENERATING_RESPONSE\",\n",
    "                'rouge1_f': 0, 'rouge1_p': 0, 'rouge1_r': 0,\n",
    "                'rouge2_f': 0, 'rougeL_f': 0\n",
    "            })\n",
    "        \n",
    "        # time.sleep(0.2) # Optional: slight delay if you encounter rate limits\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(OUTPUT_CSV_FILE_PATH, index=False)\n",
    "    print(f\"\\nResults saved to {OUTPUT_CSV_FILE_PATH}\")\n",
    "\n",
    "    if not results_df.empty:\n",
    "        # Filter out rows where ROUGE scores might be 0 due to errors/skips for accurate averaging\n",
    "        valid_scores_df = results_df[results_df['chatgpt_advice'] != \"ERROR_GENERATING_RESPONSE\"]\n",
    "        valid_scores_df = valid_scores_df[valid_scores_df['chatgpt_advice'] != \"SKIPPED_EMPTY_INPUT\"]\n",
    "\n",
    "        if not valid_scores_df.empty:\n",
    "            avg_rouge1_f = valid_scores_df['rouge1_f'].mean()\n",
    "            avg_rouge2_f = valid_scores_df['rouge2_f'].mean()\n",
    "            avg_rougeL_f = valid_scores_df['rougeL_f'].mean()\n",
    "            print(\"\\nAverage ROUGE F1-Scores (for successfully processed prompts):\")\n",
    "            print(f\"  ROUGE-1: {avg_rouge1_f:.4f}\")\n",
    "            print(f\"  ROUGE-2: {avg_rouge2_f:.4f}\")\n",
    "            print(f\"  ROUGE-L: {avg_rougeL_f:.4f}\")\n",
    "        else:\n",
    "            print(\"\\nNo prompts were successfully processed to calculate average ROUGE scores.\")\n",
    "\n",
    "# Call the main processing function\n",
    "main_notebook_processing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
